

        *** GPGPU-Sim Simulator Version 3.2.2  [build 0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N:L,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N:L,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1                     none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PreShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gmem_skip_L1D                          0 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      15 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size                   49152 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_coal_disabled                    0 # Memory Coalescing Disabled (Default is enabled)
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2                     none # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            6 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-gpgpu_compression_algo                    1 # default = 1 (BDI compression algorithm)
-gpgpu_enable_compression                    0 # default = 0 (compression is disabled by default)
-gpgpu_data_value_analysis                    0 # default = 0 (analysis is disabled by default)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBCCCCB.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file  gpuwattch_gtx480.xml # GPUWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 700.0:700.0:700.0:924.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 12
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000e100 	high:16 low:8
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000001eff 	high:13 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
sub_partition_id_mask = 0000000000000100
GPGPU-Sim uArch: clock freqs: 700000000.000000:700000000.000000:700000000.000000:924000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000142857142857:0.00000000142857142857:0.00000000142857142857:0.00000000108225108225
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 15
GPGPU-Sim uArch:    0   1   2   3   4
GPGPU-Sim uArch:    5   6   7   8   9
GPGPU-Sim uArch:   10  11  12  13  14
GPGPU-Sim uArch:   15  16  17  18  19
GPGPU-Sim uArch:   20  21  22  23  24
GPGPU-Sim uArch:   25  26
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 15
GPGPU-Sim uArch:    0   1   2   3   4
GPGPU-Sim uArch:    5   6   7   8   9
GPGPU-Sim uArch:   10  11  12  13  14
GPGPU-Sim uArch:   15  16  17  18  19
GPGPU-Sim uArch:   20  21  22  23  24
GPGPU-Sim uArch:   25  26
d2c39eec727fa28b95e3301633637b4e  /home/f85/adwait/research_bg/gpu_security/benchmarks/AES_gpgpusim/gpgpu_ptx_sim__AES_collector
GPGPU-Sim uArch: performance model initialization complete.
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=collector.cu
self exe links to: /home/f85/adwait/research_bg/gpu_security/benchmarks/AES_gpgpusim/gpgpu_ptx_sim__AES_collector
Running md5sum using "md5sum /home/f85/adwait/research_bg/gpu_security/benchmarks/AES_gpgpusim/gpgpu_ptx_sim__AES_collector "
Parsing file _cuobjdump_complete_output_w2VbDh
######### cuobjdump parser ########
## Adding new section ELF
Adding arch: sm_20
Adding identifier: collector.cu
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_20
Adding identifier: collector.cu
Done parsing!!!
GPGPU-Sim PTX: __cudaRegisterFunction _Z10read_arrayi : hostFun 0x0x4022bd, fat_cubin_handle = 1
GPGPU-Sim PTX: allocating global region for "Te0" from 0x100 to 0x900 (global memory space)
GPGPU-Sim PTX: allocating global region for "Te1" from 0x900 to 0x1100 (global memory space)
GPGPU-Sim PTX: allocating global region for "Te2" from 0x1100 to 0x1900 (global memory space)
GPGPU-Sim PTX: allocating global region for "Te3" from 0x1900 to 0x2100 (global memory space)
GPGPU-Sim PTX: allocating global region for "Te4" from 0x2100 to 0x2900 (global memory space)
GPGPU-Sim PTX: allocating global region for "ek" from 0x2900 to 0x2ae8 (global memory space)
GPGPU-Sim PTX: allocating global region for "dummy" from 0x2b00 to 0x102b00 (global memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z10cudaRunnerPhPm'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z10cudaRunnerPhPm'...
GPGPU-Sim PTX: Finding dominators for '_Z10cudaRunnerPhPm'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z10cudaRunnerPhPm'...
GPGPU-Sim PTX: Finding postdominators for '_Z10cudaRunnerPhPm'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z10cudaRunnerPhPm'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z10cudaRunnerPhPm'...
GPGPU-Sim PTX: reconvergence points for _Z10cudaRunnerPhPm...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x098 (_1.ptx:92) @%p1 bra $Lt_0_1794;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x0a0 (_1.ptx:94) mov.u64 %rd6, Te0;
GPGPU-Sim PTX: ... end of reconvergence points for _Z10cudaRunnerPhPm
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z10cudaRunnerPhPm'.
GPGPU-Sim PTX: instruction assembly for function '_Z10read_arrayi'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z10read_arrayi'...
GPGPU-Sim PTX: Finding dominators for '_Z10read_arrayi'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z10read_arrayi'...
GPGPU-Sim PTX: Finding postdominators for '_Z10read_arrayi'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z10read_arrayi'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z10read_arrayi'...
GPGPU-Sim PTX: reconvergence points for _Z10read_arrayi...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x2150 (_1.ptx:1199) @%p1 bra $Lt_1_1026;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x2188 (_1.ptx:1209) exit;
GPGPU-Sim PTX: ... end of reconvergence points for _Z10read_arrayi
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z10read_arrayi'.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file _1.ptx
Adding _cuobjdump_1.ptx with cubin handle 1
GPGPU-Sim PTX: extracting embedded .ptx to temporary file "_ptx_gnI8bq"
Running: cat _ptx_gnI8bq | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_pqYELy
GPGPU-Sim PTX: generating ptxinfo using "$CUDA_INSTALL_PATH/bin/ptxas --gpu-name=sm_20 -v _ptx2_pqYELy --output-file  /dev/null 2> _ptx_gnI8bqinfo"
GPGPU-Sim PTX: Kernel '_Z10read_arrayi' : regs=6, lmem=0, smem=0, cmem=92
GPGPU-Sim PTX: Kernel '_Z10cudaRunnerPhPm' : regs=34, lmem=0, smem=0, cmem=104
GPGPU-Sim PTX: removing ptxinfo using "rm -f _ptx_gnI8bq _ptx2_pqYELy _ptx_gnI8bqinfo"
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: __cudaRegisterFunction _Z10cudaRunnerPhPm : hostFun 0x0x402250, fat_cubin_handle = 1
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x6142c0; deviceAddress = Te0; deviceName = Te0
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 2048 bytes
GPGPU-Sim PTX registering global Te0 hostVar to name mapping
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x614ac0; deviceAddress = Te1; deviceName = Te1
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 2048 bytes
GPGPU-Sim PTX registering global Te1 hostVar to name mapping
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x6152c0; deviceAddress = Te2; deviceName = Te2
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 2048 bytes
GPGPU-Sim PTX registering global Te2 hostVar to name mapping
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x615ac0; deviceAddress = Te3; deviceName = Te3
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 2048 bytes
GPGPU-Sim PTX registering global Te3 hostVar to name mapping
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x6162c0; deviceAddress = Te4; deviceName = Te4
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 2048 bytes
GPGPU-Sim PTX registering global Te4 hostVar to name mapping
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x616ac0; deviceAddress = ek; deviceName = ek
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 488 bytes
GPGPU-Sim PTX registering constant ek (488 bytes) to name mapping
GPGPU-Sim PTX: __cudaRegisterVar: hostVar = 0x616cc0; deviceAddress = dummy; deviceName = dummy
GPGPU-Sim PTX: __cudaRegisterVar: Registering const memory space of 1048576 bytes
GPGPU-Sim PTX registering global dummy hostVar to name mapping
Num Samples:1
Num Encryption At A Time:32
entering AES_set_encrypt_key
entering AES_set_encrypt_key DONE
entering AES_set_encrypt_key GET PASSED
entering AES_set_encrypt_key retrun 0
GPGPU-Sim PTX: cudaMemcpyToSymbol: symbol = 0x6142c0
GPGPU-Sim PTX: starting gpgpu_ptx_sim_memcpy_symbol with hostVar 0x0x6142c0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: Found PTX symbol w/ hostVar=0x6142c0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: copying global memory 2048 bytes  to  symbol Te0+0 @0x100 ...
GPGPU-Sim PTX: cudaMemcpyToSymbol: symbol = 0x614ac0
GPGPU-Sim PTX: starting gpgpu_ptx_sim_memcpy_symbol with hostVar 0x0x614ac0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: Found PTX symbol w/ hostVar=0x614ac0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: copying global memory 2048 bytes  to  symbol Te1+0 @0x900 ...
GPGPU-Sim PTX: cudaMemcpyToSymbol: symbol = 0x6152c0
GPGPU-Sim PTX: starting gpgpu_ptx_sim_memcpy_symbol with hostVar 0x0x6152c0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: Found PTX symbol w/ hostVar=0x6152c0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: copying global memory 2048 bytes  to  symbol Te2+0 @0x1100 ...
GPGPU-Sim PTX: cudaMemcpyToSymbol: symbol = 0x615ac0
GPGPU-Sim PTX: starting gpgpu_ptx_sim_memcpy_symbol with hostVar 0x0x615ac0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: Found PTX symbol w/ hostVar=0x615ac0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: copying global memory 2048 bytes  to  symbol Te3+0 @0x1900 ...
GPGPU-Sim PTX: cudaMemcpyToSymbol: symbol = 0x6162c0
GPGPU-Sim PTX: starting gpgpu_ptx_sim_memcpy_symbol with hostVar 0x0x6162c0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: Found PTX symbol w/ hostVar=0x6162c0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: copying global memory 2048 bytes  to  symbol Te4+0 @0x2100 ...
GPGPU-Sim PTX: cudaMemcpyToSymbol: symbol = 0x616ac0
GPGPU-Sim PTX: starting gpgpu_ptx_sim_memcpy_symbol with hostVar 0x0x616ac0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: Found PTX symbol w/ hostVar=0x616ac0
GPGPU-Sim PTX: gpgpu_ptx_sim_memcpy_symbol: copying const memory 488 bytes  to  symbol ek+0 @0x2900 ...
83 40 c5 f7 3e d9 4b c4 46 ee 8a 03 42 1b d7 c0 
62 8f a4 da ad 7e 03 b7 d6 90 b7 1b cc f2 49 4f 
32 0f 46 70 e8 92 35 2f 80 bf 32 c2 da 09 83 3c 
98 27 16 45 a5 19 fd 7b a9 b4 96 76 a6 e0 c5 d9 
ef 0c 49 d7 9e 7e 06 1e 3d 39 e0 17 42 63 53 db 
8b 69 20 30 82 1d ac 2c d1 42 a2 78 22 67 51 11 
73 9a e9 11 19 ef 2f 56 28 10 6e 6b 73 c1 46 fe 
2b 66 2f ad 84 db d9 55 1d 7b cd 40 e3 1e 51 56 
b9 3a 68 d2 2a 97 28 52 a7 96 bd 1b 58 03 19 83 
6a 48 30 ee 23 0a 43 41 85 11 81 68 2f d2 bf e8 
0d 27 ba 37 be e3 89 66 79 47 81 d1 4a 9a 54 b4 
e3 85 a2 06 8f e6 47 14 f7 c8 7d 26 9b 3c 0f a8 
63 c9 df 21 ac 68 87 26 af 08 f7 fa a3 4c ae 86 
d1 51 8c 60 37 d4 74 2e 9c f1 54 37 2d 63 df 90 
2d be b2 d9 27 39 ff d6 42 f7 d0 e5 43 7f 6b 14 
d0 f7 74 07 cb e8 35 68 da 89 9f 07 ed 7f 98 1a 
3d 4a f3 64 83 f3 3b c5 ea 0b aa 2d 8a 15 41 5a 
0d b5 61 d8 9d 96 40 77 20 e0 7f 0d 5f 17 27 9c 
61 1a 01 e4 0d 3c aa f7 47 54 24 d2 6a 65 2c 77 
1a 8e 4f b8 24 90 2f 44 70 ae 51 cf c5 78 6b 26 
93 6c 0b a0 a8 b5 98 f0 09 bc c2 73 22 ee ea 3c 
7c 3a f4 a1 ca 24 e5 3a d2 37 09 98 af 74 be 42 
e1 c9 e3 89 7e 7b 79 88 37 3b fb 59 2a e6 96 a6 
20 8a 47 ea ae 2d 24 81 64 2d 19 13 a1 d7 56 82 
a1 39 0c 1f b4 85 a7 eb c1 a3 45 eb 89 db 91 a9 
65 d9 93 14 06 b7 95 6a e4 ae 7d 85 85 d3 08 26 
0c 14 46 c0 99 ed ac 5a 90 f1 45 19 cc d7 c2 31 
b0 55 45 b6 0c da 20 f0 88 9d 76 0e 71 7e 34 7d 
92 7a 3e 2b 68 ea 86 f8 db cb 12 a7 a2 d4 d8 52 
2a 1e 08 36 f8 28 27 81 c6 9d 8f 37 1b c3 b4 ad 
3e f2 d8 a6 dc 5e 9e b7 2a b0 5e cc 85 37 1f af 
55 27 e5 4d 50 0c ce 16 a9 5d 4d c4 21 01 71 5f 
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread

GPGPU-Sim PTX: cudaLaunch for 0x0x402250 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: pushing kernel '_Z10cudaRunnerPhPm' to stream 0, gridDim= (1,1,1) blockDim = (32,1,1) 
kernel '_Z10cudaRunnerPhPm' transfer to GPU hardware scheduler
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z10cudaRunnerPhPm'
GPGPU-Sim uArch: CTA/core = 8, limited by: cta_limit
GPGPU-Sim uArch: core:  1, cta: 0 initialized @(1,0)
GPGPU-Sim uArch: cycles simulated: 500  inst.: 352 (ipc= 0.7) sim_rate=352 (inst/sec) elapsed = 0:0:00:01 / Fri Apr 29 10:12:00 2016
GPGPU-Sim uArch: cycles simulated: 26500  inst.: 23168 (ipc= 0.9) sim_rate=11584 (inst/sec) elapsed = 0:0:00:02 / Fri Apr 29 10:12:01 2016
GPGPU-Sim uArch: cycles simulated: 59000  inst.: 51584 (ipc= 0.9) sim_rate=17194 (inst/sec) elapsed = 0:0:00:03 / Fri Apr 29 10:12:02 2016
GPGPU-Sim uArch: cycles simulated: 90500  inst.: 73440 (ipc= 0.8) sim_rate=18360 (inst/sec) elapsed = 0:0:00:04 / Fri Apr 29 10:12:03 2016
GPGPU-Sim uArch: cycles simulated: 120000  inst.: 91360 (ipc= 0.8) sim_rate=18272 (inst/sec) elapsed = 0:0:00:05 / Fri Apr 29 10:12:04 2016
GPGPU-Sim uArch: Shader 1 finished CTA #0 (133720,0), 0 CTAs running
GPGPU-Sim uArch: Shader 1 empty (release kernel 1 '_Z10cudaRunnerPhPm').
GPGPU-Sim uArch: GPU detected kernel '_Z10cudaRunnerPhPm' finished on shader 1.
kernel_name = _Z10cudaRunnerPhPm 
kernel_launch_uid = 1 
gpu_sim_cycle = 133721
gpu_sim_insn = 99136
gpu_ipc =       0.7414
gpu_tot_sim_cycle = 133721
gpu_tot_sim_insn = 99136
gpu_tot_ipc =       0.7414
gpu_tot_issued_cta = 1
gpu_stall_dramfull = 0
gpu_stall_icnt2sh    = 0
gpu_total_sim_rate=19827

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 1805
	L1I_total_cache_misses = 67
	L1I_total_cache_miss_rate = 0.0371
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 0
L1C_cache:
	L1C_total_cache_accesses = 1
	L1C_total_cache_misses = 1
	L1C_total_cache_miss_rate = 1.0000
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 0
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 1738
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 67
Shader 0 warp_id issue ditsribution:
warp_id:

distro:

gpgpu_n_tot_thrd_icount = 99168
gpgpu_n_tot_w_icount = 3099
gpgpu_n_stall_shd_mem = 2979

gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 2788
gpgpu_n_mem_write_global = 512
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 1
gpgpu_n_mem_read_inst = 67

gpgpu_n_load_insn  = 14656
gpgpu_n_store_insn = 8704
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 32
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][bk_conf] = 0
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[c_mem][data_port_stall] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][data_port_stall] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 2979
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:0	W0_Idle:155181	W0_Scoreboard:109190	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:3099
traffic_breakdown_coretomem[CONST_ACC_R] = 8 {8:1,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 22304 {8:2788,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 20480 {40:512,}
traffic_breakdown_coretomem[INST_ACC_R] = 536 {8:67,}
traffic_breakdown_memtocore[CONST_ACC_R] = 72 {72:1,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 222464 {40:1441,72:287,136:1060,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 4096 {8:512,}
traffic_breakdown_memtocore[INST_ACC_R] = 9112 {136:67,}
maxmrqlatency = 45 
maxdqlatency = 0 
maxmflatency = 390 
averagemflatency = 279 
max_icnt2mem_latency = 35 
max_icnt2sh_latency = 133720 
mrq_lat_table:2968 	330 	6 	19 	39 	6 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	726 	2575 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	1982 	1379 	7 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	895 	710 	765 	417 	2 	0 	1 	3 	7 	14 	28 	56 	113 	162 	128 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	153 	110 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        80        85         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:        85       289         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:        90        87         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:        85        66         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:        86        68         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:        94        74         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
maximum service time to same row:
dram[0]:     68425     86985         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:     76151     88797         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:     79204     90540         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:     82032     92012         0         0         0     75594         0         0         0         0         0         0         0         0         0         0 
dram[4]:     83500     93834         0         0         0     75578         0         0         0         0         0         0         0         0         0         0 
dram[5]:     85266     95340         0         0         0         0    124876         0         0         0         0         0         0         0         0         0 
average row accesses per activate:
dram[0]: 20.000000 21.888889      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[1]: 25.799999 50.555557      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[2]: 32.500000 21.333334      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[3]: 20.666666 21.777779      -nan      -nan      -nan 256.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[4]: 21.166666 23.125000      -nan      -nan      -nan 256.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
dram[5]: 24.222221 23.625000      -nan      -nan      -nan      -nan  4.000000      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 
average row locality = 3368/116 = 29.034483
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       200       197         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:       258       199         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:       260       192         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:       248       196         0         0         0       128         0         0         0         0         0         0         0         0         0         0 
dram[4]:       254       185         0         0         0       128         0         0         0         0         0         0         0         0         0         0 
dram[5]:       218       189         0         0         0         0         4         0         0         0         0         0         0         0         0         0 
total reads: 2856
min_bank_accesses = 0!
chip skew: 572/397 = 1.44
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0       256         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0       128         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0       128         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total writes: 512
min_bank_accesses = 0!
min_chip_accesses = 0!
average mf latency per bank:
dram[0]:        266       279    none      none      none      none      none      none      none      none      none      none      none      none      none      none  
dram[1]:        286       258    none      none      none      none      none      none      none      none      none      none      none      none      none      none  
dram[2]:        284       269    none      none      none      none      none      none      none      none      none      none      none      none      none      none  
dram[3]:        278       283    none      none      none         267    none      none      none      none      none      none      none      none      none      none  
dram[4]:        276       280    none      none      none         259    none      none      none      none      none      none      none      none      none      none  
dram[5]:        285       272    none      none      none      none         262    none      none      none      none      none      none      none      none      none  
maximum mf latency per bank:
dram[0]:        358       379         0         0         0         0         0         0         0         0         0         0         0         0         0         0
dram[1]:        376       375         0         0         0         0         0         0         0         0         0         0         0         0         0         0
dram[2]:        384       367         0         0         0         0         0         0         0         0         0         0         0         0         0         0
dram[3]:        369       390         0         0         0       290         0         0         0         0         0         0         0         0         0         0
dram[4]:        371       386         0         0         0       281         0         0         0         0         0         0         0         0         0         0
dram[5]:        377       358         0         0         0         0       271         0         0         0         0         0         0         0         0         0

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
Memory Partition 0: 
In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=176511 n_nop=175900 n_act=20 n_pre=18 n_req=397 n_rd=573 n_write=0 nbytes_uncomp=36672 nbytes_comp=36672 bw_util=0.006493
toggles=93196, zeros=308858, ones=97670, tot_bits=406528
zero_per=0.7597
avg_bit_diff=532
hist_bit_diff = 0	0	0	0	0	0.8892	0.07809	0	0	0	0.03275	
n_activity=4453 dram_eff=0.2574
bk0: 277a 175768i bk1: 296a 175674i bk2: 0a 176493i bk3: 0a 176495i bk4: 0a 176499i bk5: 0a 176503i bk6: 0a 176507i bk7: 0a 176508i bk8: 0a 176510i bk9: 0a 176511i bk10: 0a 176512i bk11: 0a 176514i bk12: 0a 176518i bk13: 0a 176518i bk14: 0a 176521i bk15: 0a 176526i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=1 avg=0.00147866
Memory Partition 1: 
In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=176511 n_nop=175540 n_act=21 n_pre=19 n_req=713 n_rd=675 n_write=256 nbytes_uncomp=59584 nbytes_comp=59584 bw_util=0.01055
toggles=155246, zeros=581643, ones=148469, tot_bits=730112
zero_per=0.7966
avg_bit_diff=607.5
hist_bit_diff = 0	0	0	0	0	0.5792	0.09257	0.08135	0.1823	0.03506	0.02945	
n_activity=7883 dram_eff=0.2362
bk0: 373a 175530i bk1: 302a 175372i bk2: 0a 176491i bk3: 0a 176496i bk4: 0a 176501i bk5: 0a 176507i bk6: 0a 176510i bk7: 0a 176510i bk8: 0a 176510i bk9: 0a 176512i bk10: 0a 176512i bk11: 0a 176512i bk12: 0a 176513i bk13: 0a 176515i bk14: 0a 176520i bk15: 0a 176527i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=2 avg=0.00164862
Memory Partition 2: 
In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=176511 n_nop=175811 n_act=19 n_pre=17 n_req=452 n_rd=664 n_write=0 nbytes_uncomp=42496 nbytes_comp=42496 bw_util=0.007524
toggles=109108, zeros=352574, ones=110274, tot_bits=462848
zero_per=0.7617
avg_bit_diff=536.1
hist_bit_diff = 0	0	0	0	0	0.7611	0.2124	0	0	0	0.02655	
n_activity=4992 dram_eff=0.266
bk0: 379a 175568i bk1: 285a 175690i bk2: 0a 176495i bk3: 0a 176500i bk4: 0a 176503i bk5: 0a 176505i bk6: 0a 176508i bk7: 0a 176508i bk8: 0a 176508i bk9: 0a 176511i bk10: 0a 176513i bk11: 0a 176514i bk12: 0a 176515i bk13: 0a 176516i bk14: 0a 176521i bk15: 0a 176522i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=1 avg=0.00163729
Memory Partition 3: 
In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=176511 n_nop=175602 n_act=24 n_pre=21 n_req=700 n_rd=736 n_write=128 nbytes_uncomp=55296 nbytes_comp=55296 bw_util=0.00979
toggles=132403, zeros=474006, ones=242794, tot_bits=716800
zero_per=0.6613
avg_bit_diff=330.7
hist_bit_diff = 0.3657	0	0	0	0.04143	0.5771	0	0	0	0	0.01571	
n_activity=6202 dram_eff=0.2786
bk0: 337a 175605i bk1: 271a 175680i bk2: 0a 176492i bk3: 0a 176496i bk4: 0a 176502i bk5: 128a 176073i bk6: 0a 176505i bk7: 0a 176508i bk8: 0a 176510i bk9: 0a 176510i bk10: 0a 176511i bk11: 0a 176514i bk12: 0a 176515i bk13: 0a 176518i bk14: 0a 176524i bk15: 0a 176525i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=5 avg=0.0024871
Memory Partition 4: 
In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=176511 n_nop=175592 n_act=23 n_pre=20 n_req=695 n_rd=748 n_write=128 nbytes_uncomp=56064 nbytes_comp=56064 bw_util=0.009926
toggles=132049, zeros=473848, ones=237832, tot_bits=711680
zero_per=0.6658
avg_bit_diff=345.6
hist_bit_diff = 0.3453	0.02302	0	0	0.04173	0.4446	0.1309	0	0	0	0.01439	
n_activity=6192 dram_eff=0.2829
bk0: 359a 175518i bk1: 261a 175777i bk2: 0a 176497i bk3: 0a 176501i bk4: 0a 176503i bk5: 128a 176088i bk6: 0a 176506i bk7: 0a 176507i bk8: 0a 176509i bk9: 0a 176510i bk10: 0a 176511i bk11: 0a 176514i bk12: 0a 176516i bk13: 0a 176517i bk14: 0a 176519i bk15: 0a 176524i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=5 avg=0.00296299
Memory Partition 5: 
In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=176511 n_nop=175887 n_act=20 n_pre=17 n_req=411 n_rd=587 n_write=0 nbytes_uncomp=37568 nbytes_comp=37568 bw_util=0.006651
toggles=95252, zeros=319134, ones=101730, tot_bits=420864
zero_per=0.7583
avg_bit_diff=529
hist_bit_diff = 0	0	0	0	0	0.8978	0.06813	0	0	0	0.03406	
n_activity=4719 dram_eff=0.2488
bk0: 317a 175639i bk1: 266a 175774i bk2: 0a 176498i bk3: 0a 176504i bk4: 0a 176504i bk5: 0a 176505i bk6: 4a 176488i bk7: 0a 176504i bk8: 0a 176507i bk9: 0a 176511i bk10: 0a 176514i bk11: 0a 176514i bk12: 0a 176516i bk13: 0a 176519i bk14: 0a 176519i bk15: 0a 176520i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=2 avg=0.00186391

icnt_total_pkts_mem_to_simt=9893
icnt_total_pkts_simt_to_mem=3880
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 20.3487
	minimum = 6
	maximum = 128
Network latency average = 19.5242
	minimum = 6
	maximum = 127
Slowest packet = 1665
Flit latency average = 23.4657
	minimum = 6
	maximum = 125
Slowest flit = 8372
Fragmentation average = 0
	minimum = 0
	maximum = 0
Injected packet rate average = 0.00186569
	minimum = 0 (at node 0)
	maximum = 0.0251868 (at node 1)
Accepted packet rate average = 0.00186569
	minimum = 0 (at node 0)
	maximum = 0.0251868 (at node 1)
Injected flit rate average = 0.00381474
	minimum = 0 (at node 0)
	maximum = 0.0290156 (at node 1)
Accepted flit rate average= 0.00381474
	minimum = 0 (at node 0)
	maximum = 0.0739824 (at node 1)
Injected packet length average = 2.04469
Accepted packet length average = 2.04469
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 20.3487 (1 samples)
	minimum = 6 (1 samples)
	maximum = 128 (1 samples)
Network latency average = 19.5242 (1 samples)
	minimum = 6 (1 samples)
	maximum = 127 (1 samples)
Flit latency average = 23.4657 (1 samples)
	minimum = 6 (1 samples)
	maximum = 125 (1 samples)
Fragmentation average = 0 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0 (1 samples)
Injected packet rate average = 0.00186569 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0251868 (1 samples)
Accepted packet rate average = 0.00186569 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0251868 (1 samples)
Injected flit rate average = 0.00381474 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0290156 (1 samples)
Accepted flit rate average = 0.00381474 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0739824 (1 samples)
Injected packet size average = 2.04469 (1 samples)
Accepted packet size average = 2.04469 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 5 sec (5 sec)
gpgpu_simulation_rate = 19827 (inst/sec)
gpgpu_simulation_rate = 26744 (cycle/sec)
0
done
